{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise comparativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparação de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Configurações iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from IPython.display import Markdown\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lendo o conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data/raw/hour.csv')\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lendo dicionário de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_path = Path('../data/external/dicionario.csv')\n",
    "df_dict = pd.read_csv(dict_path, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Tratamento de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada tipo de variável, será criado um pipeline para pré-processamento com os seguintes itens:\n",
    "- Tratamento de dados discrepantes\n",
    "- Tratamento de dados faltantes\n",
    "- Codificação de variáveis\n",
    "- Seleção de variáveis\n",
    "- Normalização\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'cnt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variáveis discretas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instant', 'casual', 'registered']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_columns = (\n",
    "    df_dict\n",
    "    .query('Subtipo == \"Discreta\" and Variável != @target_column')\n",
    "    ['Variável']\n",
    "    .to_list()\n",
    ")\n",
    "\n",
    "discrete_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_preprocessor = Pipeline([\n",
    "    # Tratamento de dados discrepantes\n",
    "    ('missing', SimpleImputer(strategy='mean')), # Tratamento de dados faltantes\n",
    "    # Seleção de variáveis\n",
    "    ('normalization', MinMaxScaler()) # Normalização\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variáveis contínuas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temp', 'atemp', 'hum', 'windspeed']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_columns = (\n",
    "    df_dict\n",
    "    .query('Subtipo == \"Contínua\"')\n",
    "    ['Variável']\n",
    "    .to_list()\n",
    ")\n",
    "\n",
    "continuous_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_preprocessor = Pipeline(steps=[\n",
    "    # Tratamento de dados discrepantes\n",
    "    ('missing', KNNImputer(n_neighbors=5)), # Tratamento de dados faltantes\n",
    "    # Seleção de variáveis\n",
    "    ('normalization', RobustScaler()) # Normalização\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variáveis nominais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['holiday', 'workingday']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nominal_columns = (\n",
    "    df_dict\n",
    "    .query('Subtipo == \"Nominal\"')\n",
    "    ['Variável']\n",
    "    .to_list()\n",
    ")\n",
    "\n",
    "nominal_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_preprocessor = Pipeline([\n",
    "    # Tratamento de dados discrepantes\n",
    "    ('missing', SimpleImputer(strategy='most_frequent')), # Tratamento de dados faltantes\n",
    "    ('encoder', OneHotEncoder(sparse=False)), # Codificação de variáveis\n",
    "    # Seleção de variáveis\n",
    "    ('normalization', MinMaxScaler()), # Normalização    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variáveis ordinais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dteday', 'season', 'yr', 'mnth', 'hr', 'weekday', 'weathersit']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_columns = (\n",
    "    df_dict\n",
    "    .query('Subtipo == \"Ordinal\"')\n",
    "    ['Variável']\n",
    "    .to_list()\n",
    ")\n",
    "\n",
    "ordinal_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_preprocessor = Pipeline([\n",
    "    # Tratamento de dados discrepantes\n",
    "    ('missing', SimpleImputer(strategy='most_frequent')), # Tratamento de dados faltantes\n",
    "    ('encoder', OrdinalEncoder()), # Codificação de variáveis\n",
    "    # Seleção de variáveis\n",
    "    ('normalization', MinMaxScaler()), # Normalização    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando pré-processadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = ColumnTransformer([\n",
    "    (\"discrete\", discrete_preprocessor, discrete_columns),\n",
    "    # (\"continuous\", continuous_preprocessor, continuous_columns),\n",
    "    # (\"nominal\", nominal_preprocessor, nominal_columns)\n",
    "    (\"ordinal\", ordinal_preprocessor, ordinal_columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Escolha do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Metodologia\n",
    "Iremos análisar quatro modelos, que serão testados utilizando um método de validação cruzada por permutação, os modelos que serão testados serão: \n",
    "\n",
    "- Logistic Regression (LR)\n",
    "- K-Nearest-Neighbors (KNN)\n",
    "- Support Vector Machine (SVM)\n",
    "- Naive Bayes (NB)\n",
    "\n",
    "Além disso, cada um desses algoritmos será testado com diferentes parametros, para que possamos encontrar o melhor modelo e a melhor configuração possível para esse modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos serão comparados através dos seguintes parâmetros\n",
    "- `accuracy`: Proporção entre os dados que foram corretamente previstos (como positivos ou negativos) com o total de dados observados\n",
    "\n",
    "- `precision` : Proporção entre dados corretamente previstos como positivos e o total de observações positivas. Ou seja, de todos os pacientes que identificamos com câncer, quantos realmente possuem?\n",
    "\n",
    "- `recall`: Proporção entre dados corretamente previstos como positivos com o total de observações. Ou seja, entre todos os pacientes que possuem câncem pulmonar, quantos foram marcados? Em outras palavras, esse parâmetro ajuda a identificar a sensibilidade do nosso modelo\n",
    "\n",
    "- `f1`: Média ponderada entre `precision` e `recall`, portanto levando em conta tanto falsos positivos quanto falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        \"LR\", #Nome do modelo (abreviado)\n",
    "        LogisticRegression(solver='saga', max_iter=1000), # Chamada do método do modelo\n",
    "        {\"penalty\": ['none', 'l1', 'l2']} # Diferentes parametros que serão testados\n",
    "    ),\n",
    "    (\n",
    "        \"KNN\",\n",
    "        KNeighborsClassifier(metric='euclidean'),\n",
    "        {\"n_neighbors\": np.arange(1, 31, 2), 'weights': [\"uniform\", \"distance\"]}\n",
    "    ),\n",
    "    (\n",
    "        \"SVM\",\n",
    "        SVC(max_iter=10000),\n",
    "        {'C':[1, 10, 100, 1000],'gamma':[1, 0.1, 0.001, 0.0001], 'kernel':['linear','rbf']}\n",
    "    ),\n",
    "    (\n",
    "        \"NB\",\n",
    "        BernoulliNB(),\n",
    "        {\"alpha\": [1e-3, 0.5, 1]}\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Configuração do experimento\n",
    "Iremos separar o conjunto de dados em conjunto de testes e de treino para realizar a validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[target_column], axis=1)\n",
    "y = (\n",
    "    df[[target_column]]\n",
    "    # .replace({\"YES\": 1, \"NO\": 0})\n",
    "    .to_numpy()\n",
    "    .ravel()\n",
    ")\n",
    "\n",
    "# Fazer a separação levando em conta a ordem dos dados\n",
    "cv = ShuffleSplit(n_splits=30, train_size=0.8, random_state=42) #Separa em conjuntos de teste e treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora iremos realizar o teste com os modelos definidos anteriormente, testando também os diferentes parâmetros para obter a melhor combinação possível. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wesley/.cache/pypoetry/virtualenvs/src-JujeFAdE-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/wesley/.cache/pypoetry/virtualenvs/src-JujeFAdE-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/wesley/.cache/pypoetry/virtualenvs/src-JujeFAdE-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/wesley/.cache/pypoetry/virtualenvs/src-JujeFAdE-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/wesley/dev/BikeCD/notebooks/02-comparative_analysis.ipynb Cell 39\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/wesley/dev/BikeCD/notebooks/02-comparative_analysis.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m model_gs \u001b[39m=\u001b[39m GridSearchCV(model, model_params, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/wesley/dev/BikeCD/notebooks/02-comparative_analysis.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m approach \u001b[39m=\u001b[39m Pipeline([\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/wesley/dev/BikeCD/notebooks/02-comparative_analysis.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mpreprocessing\u001b[39m\u001b[39m\"\u001b[39m, preprocessing),\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/wesley/dev/BikeCD/notebooks/02-comparative_analysis.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, model_gs)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/wesley/dev/BikeCD/notebooks/02-comparative_analysis.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m ])\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/wesley/dev/BikeCD/notebooks/02-comparative_analysis.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m model_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/wesley/dev/BikeCD/notebooks/02-comparative_analysis.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     approach,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/wesley/dev/BikeCD/notebooks/02-comparative_analysis.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/wesley/dev/BikeCD/notebooks/02-comparative_analysis.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/wesley/dev/BikeCD/notebooks/02-comparative_analysis.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     scoring\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mf1\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrecall\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m#Critérios de avaliação\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/wesley/dev/BikeCD/notebooks/02-comparative_analysis.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/wesley/dev/BikeCD/notebooks/02-comparative_analysis.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/wesley/dev/BikeCD/notebooks/02-comparative_analysis.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     return_train_score\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/wesley/dev/BikeCD/notebooks/02-comparative_analysis.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/wesley/dev/BikeCD/notebooks/02-comparative_analysis.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m model_results[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [model_name] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(model_results[\u001b[39m'\u001b[39m\u001b[39mscore_time\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/wesley/dev/BikeCD/notebooks/02-comparative_analysis.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mif\u001b[39;00m results:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-JujeFAdE-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-JujeFAdE-py3.8/lib/python3.8/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-JujeFAdE-py3.8/lib/python3.8/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-JujeFAdE-py3.8/lib/python3.8/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 439\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for model_name, model, model_params in models:\n",
    "    print(f'{model_name} run...')\n",
    "    \n",
    "    model_gs = GridSearchCV(model, model_params, scoring='accuracy')\n",
    "    approach = Pipeline([\n",
    "        (\"preprocessing\", preprocessing),\n",
    "        (\"model\", model_gs)\n",
    "    ])\n",
    "    model_results = cross_validate(\n",
    "        approach,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        scoring=['accuracy', 'f1', 'precision', 'recall'], #Critérios de avaliação\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    model_results['name'] = [model_name] * len(model_results['score_time'])\n",
    "    if results:\n",
    "        for key, value in model_results.items():\n",
    "            results[key] = np.append(results[key], value)\n",
    "    else:\n",
    "        results = model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Resultados\n",
    "Aqui iremos comparar os resultados e definir um modelo para ser utilizado no projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results.groupby('name').agg([np.mean, np.std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma tabela para melhor visualizar e comparar os modelos \n",
    "\n",
    "def highlight_max(s, props=''):\n",
    "    values = [float(value.split()[0]) for value in s.values[1:]]\n",
    "    result = [''] * len(s.values)\n",
    "    if s.values[0].endswith('time'):\n",
    "        result[np.argmin(values)+1] = props\n",
    "    else:\n",
    "        result[np.argmax(values)+1] = props\n",
    "    return result\n",
    "\n",
    "def get_winner(s):\n",
    "    metric = s.values[0]\n",
    "    values = [float(value.split()[0]) for value in s.values[1:]]\n",
    "    models = results.columns[1:]\n",
    "    \n",
    "    if s.values[0].endswith('time'):\n",
    "        return models[np.argmin(values)]\n",
    "    else:\n",
    "        return models[np.argmax(values)]\n",
    "\n",
    "results = (\n",
    "    pd\n",
    "    .DataFrame(df_results)\n",
    "    .groupby(['name'])\n",
    "    .agg([lambda x: f\"{np.mean(x):.3f} ± {np.std(x):.3f}\"])#\n",
    "    .transpose()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_0\": \"score\"})\n",
    "    .drop(columns=\"level_1\")\n",
    "    # .set_index('score')\n",
    ")\n",
    "time_scores = ['fit_time', 'score_time']\n",
    "winner = results.query('score not in @time_scores').apply(get_winner, axis=1).value_counts().index[0]\n",
    "results.columns.name = ''\n",
    "results = (\n",
    "    results\n",
    "    .style\n",
    "    .hide(axis='index')\n",
    "    .apply(highlight_max, props='color:white;background-color:gray', axis=1)\n",
    ")\n",
    "display(results)\n",
    "display(Markdown(f'### O melhor modelo é o : **{winner}**'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Persistência do modelo\n",
    "Dado que já obtivemos o melhor modelo agora podemos obter os melhores parâmetros desse modelo e salvar esse modelo em disco para utilizar na pŕóxima fase da análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtem o modelo e os parametros ganhadores\n",
    "model_name, model, model_params  = [foo for foo in models if foo[0] == winner][0] \n",
    "\n",
    "model_gs = GridSearchCV(model, model_params, scoring='accuracy')\n",
    "approach = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"model\", model_gs)\n",
    "])\n",
    "approach.fit(X, y) #Seleciona o approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(approach, '../models/model.joblib') # Salva o modelo em disco"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src-JujeFAdE-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
